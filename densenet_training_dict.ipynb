{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjyX2mtD4NsrLH7RMEzMgG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumik12345/wandb-addons/blob/examples%2Fmonai/densenet_training_dict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "26gwSEmtgfQ9"
      },
      "outputs": [],
      "source": [
        "!mkdir dataset\n",
        "%cd dataset\n",
        "!wget http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI-T1.tar\n",
        "!wget http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI-T2.tar\n",
        "!tar -xf IXI-T1.tar && tar -xf IXI-T2.tar && rm -rf IXI-T1.tar && rm -rf IXI-T2.tar\n",
        "%cd ..\n",
        "!git clone https://github.com/soumik12345/wandb-addons -b integration/monai/checkpoint\n",
        "!pip install -q --upgrade pip setuptools\n",
        "!pip install -q -e wandb-addons[monai]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from glob import glob\n",
        "\n",
        "import numpy as np\n",
        "import wandb\n",
        "import torch\n",
        "from ignite.engine import Events, _prepare_batch, create_supervised_evaluator, create_supervised_trainer\n",
        "from ignite.handlers import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "import monai\n",
        "from monai.data import decollate_batch, DataLoader\n",
        "from monai.handlers import ROCAUC, StatsHandler, TensorBoardStatsHandler, stopping_fn_from_metric\n",
        "from monai.transforms import Activations, AsDiscrete, Compose, LoadImaged, RandRotate90d, Resized, ScaleIntensityd\n",
        "\n",
        "monai.config.print_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCnXLAtwg0gZ",
        "outputId": "75b13d2b-0bc7-40ca-c5b6-1ac325f45888"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MONAI version: 1.2.dev2312\n",
            "Numpy version: 1.22.4\n",
            "Pytorch version: 1.13.1+cu116\n",
            "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
            "MONAI rev id: 400a6a052f1b2925db6f1323a67a7cf4546403eb\n",
            "MONAI __file__: /usr/local/lib/python3.9/dist-packages/monai/__init__.py\n",
            "\n",
            "Optional dependencies:\n",
            "Pytorch Ignite version: 0.4.11\n",
            "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "Nibabel version: 3.0.2\n",
            "scikit-image version: 0.19.3\n",
            "Pillow version: 8.4.0\n",
            "Tensorboard version: 2.11.2\n",
            "gdown version: 4.6.4\n",
            "TorchVision version: 0.14.1+cu116\n",
            "tqdm version: 4.65.0\n",
            "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "psutil version: 5.9.4\n",
            "pandas version: 1.4.4\n",
            "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "\n",
            "For details about installing the optional dependencies, please visit:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.tensorboard.patch(root_logdir=\"./runs\")\n",
        "wandb.init(project=\"monai-integration\", sync_tensorboard=True, save_code=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "N3Wb513Wg6xu",
        "outputId": "1a9329e5-ecb9-4422-8fa3-84e9449426bc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgeekyrakshit\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230323_140053-2dr2i4y3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/geekyrakshit/monai-integration/runs/2dr2i4y3' target=\"_blank\">peachy-valley-33</a></strong> to <a href='https://wandb.ai/geekyrakshit/monai-integration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/geekyrakshit/monai-integration' target=\"_blank\">https://wandb.ai/geekyrakshit/monai-integration</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/geekyrakshit/monai-integration/runs/2dr2i4y3' target=\"_blank\">https://wandb.ai/geekyrakshit/monai-integration/runs/2dr2i4y3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/geekyrakshit/monai-integration/runs/2dr2i4y3?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f2b23329190>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = glob(\"./dataset/*\")[:20]\n",
        "labels = np.array([0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0], dtype=np.int64)\n",
        "train_files = [{\"img\": img, \"label\": label} for img, label in zip(images[:10], labels[:10])]\n",
        "val_files = [{\"img\": img, \"label\": label} for img, label in zip(images[-10:], labels[-10:])]"
      ],
      "metadata": {
        "id": "zr8X-sMTg8TX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"img\"], ensure_channel_first=True),\n",
        "        ScaleIntensityd(keys=[\"img\"]),\n",
        "        Resized(keys=[\"img\"], spatial_size=(96, 96, 96)),\n",
        "        RandRotate90d(keys=[\"img\"], prob=0.8, spatial_axes=[0, 2]),\n",
        "    ]\n",
        ")\n",
        "val_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"img\"], ensure_channel_first=True),\n",
        "        ScaleIntensityd(keys=[\"img\"]),\n",
        "        Resized(keys=[\"img\"], spatial_size=(96, 96, 96)),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EZsKs1bg-Hh",
        "outputId": "c8111505-494c-4633-ac74-706560c8ef79"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.io.dictionary LoadImaged.__init__:image_only: Current default value of argument `image_only=False` has been deprecated since version 1.1. It will be changed to `image_only=True` in version 1.3.\n",
            "  warn_deprecated(argname, msg, warning_category)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
        "check_loader = DataLoader(check_ds, batch_size=2, num_workers=4, pin_memory=torch.cuda.is_available())\n",
        "check_data = monai.utils.misc.first(check_loader)\n",
        "print(check_data[\"img\"].shape, check_data[\"label\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvJAkTG3hAw1",
        "outputId": "cd1b4ae3-79b0-4903-9993-354f8b158c4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1, 96, 96, 96]) tensor([0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = monai.networks.nets.DenseNet121(spatial_dims=3, in_channels=1, out_channels=2).to(device)\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "lr = 1e-5\n",
        "opt = torch.optim.Adam(net.parameters(), lr)"
      ],
      "metadata": {
        "id": "GFwPD23chCBO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_batch(batch, device=None, non_blocking=False):\n",
        "    return _prepare_batch((batch[\"img\"], batch[\"label\"]), device, non_blocking)\n",
        "\n",
        "trainer = create_supervised_trainer(net, opt, loss, device, False, prepare_batch=prepare_batch)"
      ],
      "metadata": {
        "id": "plfCRpwjhDU1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_handler = WandbModelCheckpointHandler(\"./runs_dict/\", \"net\", n_saved=10, require_empty=False)\n",
        "trainer.add_event_handler(\n",
        "    event_name=Events.EPOCH_COMPLETED, handler=checkpoint_handler, to_save={\"net\": net, \"opt\": opt}\n",
        ")\n",
        "\n",
        "train_stats_handler = StatsHandler(name=\"trainer\", output_transform=lambda x: x)\n",
        "train_stats_handler.attach(trainer)\n",
        "\n",
        "train_tensorboard_stats_handler = TensorBoardStatsHandler(output_transform=lambda x: x)\n",
        "train_tensorboard_stats_handler.attach(trainer)"
      ],
      "metadata": {
        "id": "UyRWH-xchEfT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # set parameters for validation\n",
        "validation_every_n_epochs = 1\n",
        "\n",
        "metric_name = \"AUC\"\n",
        "# add evaluation metric to the evaluator engine\n",
        "val_metrics = {metric_name: ROCAUC()}\n",
        "\n",
        "post_label = Compose([AsDiscrete(to_onehot=2)])\n",
        "post_pred = Compose([Activations(softmax=True)])\n",
        "# Ignite evaluator expects batch=(img, label) and returns output=(y_pred, y) at every iteration,\n",
        "# user can add output_transform to return other values\n",
        "evaluator = create_supervised_evaluator(\n",
        "    net,\n",
        "    val_metrics,\n",
        "    device,\n",
        "    True,\n",
        "    prepare_batch=prepare_batch,\n",
        "    output_transform=lambda x, y, y_pred: (\n",
        "        [post_pred(i) for i in decollate_batch(y_pred)],\n",
        "        [post_label(i) for i in decollate_batch(y, detach=False)],\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "n-SlJCAphF8D"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add stats event handler to print validation stats via evaluator\n",
        "val_stats_handler = StatsHandler(\n",
        "    name=\"evaluator\",\n",
        "    output_transform=lambda x: None,  # no need to print loss value, so disable per iteration output\n",
        "    global_epoch_transform=lambda x: trainer.state.epoch,\n",
        ")  # fetch global epoch number from trainer\n",
        "val_stats_handler.attach(evaluator)\n",
        "\n",
        "# add handler to record metrics to TensorBoard at every epoch\n",
        "val_tensorboard_stats_handler = TensorBoardStatsHandler(\n",
        "    output_transform=lambda x: None,  # no need to plot loss value, so disable per iteration output\n",
        "    global_epoch_transform=lambda x: trainer.state.epoch,\n",
        ")  # fetch global epoch number from trainer\n",
        "val_tensorboard_stats_handler.attach(evaluator)"
      ],
      "metadata": {
        "id": "QnH1hXpBhHUT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add early stopping handler to evaluator\n",
        "early_stopper = EarlyStopping(patience=4, score_function=stopping_fn_from_metric(metric_name), trainer=trainer)\n",
        "evaluator.add_event_handler(event_name=Events.EPOCH_COMPLETED, handler=early_stopper)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erb5BjZbhIqf",
        "outputId": "9883dabd-f67e-496b-a75a-a1d46565170c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ignite.engine.events.RemovableEventHandle at 0x7f2b20dd7610>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a validation data loader\n",
        "val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
        "val_loader = DataLoader(val_ds, batch_size=2, num_workers=4, pin_memory=torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "_qIxL_rDhKBe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@trainer.on(Events.EPOCH_COMPLETED(every=validation_every_n_epochs))\n",
        "def run_validation(engine):\n",
        "    evaluator.run(val_loader)"
      ],
      "metadata": {
        "id": "FSj-EcxLhLRJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a training data loader\n",
        "train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
        "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=4, pin_memory=torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "f1jqVXrphMcs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_epochs = 30\n",
        "state = trainer.run(train_loader, train_epochs)\n",
        "print(state)\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VGdPBlG1hNj1",
        "outputId": "cc10a268-a533-4fff-d500-f4f547abbf77"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-23 14:01:44,550 - INFO - Epoch: 1/30, Iter: 1/5 -- Loss: 0.6107 \n",
            "2023-03-23 14:01:44,787 - INFO - Epoch: 1/30, Iter: 2/5 -- Loss: 0.6475 \n",
            "2023-03-23 14:01:45,014 - INFO - Epoch: 1/30, Iter: 3/5 -- Loss: 0.5805 \n",
            "2023-03-23 14:01:45,249 - INFO - Epoch: 1/30, Iter: 4/5 -- Loss: 0.6555 \n",
            "2023-03-23 14:01:45,486 - INFO - Epoch: 1/30, Iter: 5/5 -- Loss: 0.6068 \n",
            "2023-03-23 14:01:51,314 - INFO - Epoch[1] Metrics -- AUC: 0.4167 \n",
            "2023-03-23 14:01:55,667 - INFO - Epoch: 2/30, Iter: 1/5 -- Loss: 0.7619 \n",
            "2023-03-23 14:01:55,954 - INFO - Epoch: 2/30, Iter: 2/5 -- Loss: 0.5989 \n",
            "2023-03-23 14:01:56,251 - INFO - Epoch: 2/30, Iter: 3/5 -- Loss: 0.5601 \n",
            "2023-03-23 14:01:56,480 - INFO - Epoch: 2/30, Iter: 4/5 -- Loss: 0.5078 \n",
            "2023-03-23 14:01:56,709 - INFO - Epoch: 2/30, Iter: 5/5 -- Loss: 0.6045 \n",
            "2023-03-23 14:02:02,048 - INFO - Epoch[2] Metrics -- AUC: 0.5833 \n",
            "2023-03-23 14:02:06,596 - INFO - Epoch: 3/30, Iter: 1/5 -- Loss: 0.7187 \n",
            "2023-03-23 14:02:07,052 - INFO - Epoch: 3/30, Iter: 2/5 -- Loss: 0.5903 \n",
            "2023-03-23 14:02:07,578 - INFO - Epoch: 3/30, Iter: 3/5 -- Loss: 0.6031 \n",
            "2023-03-23 14:02:07,908 - INFO - Epoch: 3/30, Iter: 4/5 -- Loss: 0.5969 \n",
            "2023-03-23 14:02:08,152 - INFO - Epoch: 3/30, Iter: 5/5 -- Loss: 0.4632 \n",
            "2023-03-23 14:02:12,725 - INFO - Epoch[3] Metrics -- AUC: 0.5000 \n",
            "2023-03-23 14:02:16,030 - INFO - Epoch: 4/30, Iter: 1/5 -- Loss: 0.6063 \n",
            "2023-03-23 14:02:16,362 - INFO - Epoch: 4/30, Iter: 2/5 -- Loss: 0.4686 \n",
            "2023-03-23 14:02:16,657 - INFO - Epoch: 4/30, Iter: 3/5 -- Loss: 0.4682 \n",
            "2023-03-23 14:02:16,896 - INFO - Epoch: 4/30, Iter: 4/5 -- Loss: 0.5713 \n",
            "2023-03-23 14:02:17,127 - INFO - Epoch: 4/30, Iter: 5/5 -- Loss: 0.8078 \n",
            "2023-03-23 14:02:23,670 - INFO - Epoch[4] Metrics -- AUC: 0.5833 \n",
            "2023-03-23 14:02:27,047 - INFO - Epoch: 5/30, Iter: 1/5 -- Loss: 0.8960 \n",
            "2023-03-23 14:02:27,388 - INFO - Epoch: 5/30, Iter: 2/5 -- Loss: 0.3522 \n",
            "2023-03-23 14:02:27,691 - INFO - Epoch: 5/30, Iter: 3/5 -- Loss: 0.5076 \n",
            "2023-03-23 14:02:27,934 - INFO - Epoch: 5/30, Iter: 4/5 -- Loss: 0.5832 \n",
            "2023-03-23 14:02:28,163 - INFO - Epoch: 5/30, Iter: 5/5 -- Loss: 0.5658 \n",
            "2023-03-23 14:02:33,308 - INFO - Epoch[5] Metrics -- AUC: 0.5417 \n",
            "2023-03-23 14:02:37,745 - INFO - Epoch: 6/30, Iter: 1/5 -- Loss: 0.6066 \n",
            "2023-03-23 14:02:38,055 - INFO - Epoch: 6/30, Iter: 2/5 -- Loss: 0.7201 \n",
            "2023-03-23 14:02:38,359 - INFO - Epoch: 6/30, Iter: 3/5 -- Loss: 0.9214 \n",
            "2023-03-23 14:02:38,611 - INFO - Epoch: 6/30, Iter: 4/5 -- Loss: 0.5746 \n",
            "2023-03-23 14:02:38,843 - INFO - Epoch: 6/30, Iter: 5/5 -- Loss: 0.5829 \n",
            "2023-03-23 14:02:43,820 - INFO - Epoch[6] Metrics -- AUC: 0.4583 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-03-23 14:02:43,824 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State:\n",
            "\titeration: 30\n",
            "\tepoch: 6\n",
            "\tepoch_length: 5\n",
            "\tmax_epochs: 30\n",
            "\toutput: 0.5829094648361206\n",
            "\tbatch: <class 'dict'>\n",
            "\tmetrics: <class 'dict'>\n",
            "\tdataloader: <class 'monai.data.dataloader.DataLoader'>\n",
            "\tseed: <class 'NoneType'>\n",
            "\ttimes: <class 'dict'>\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AUC</td><td>▁█▅█▆▃</td></tr><tr><td>global_step</td><td>▁▂▄▅▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AUC</td><td>0.45833</td></tr><tr><td>global_step</td><td>6</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">peachy-valley-33</strong> at: <a href='https://wandb.ai/geekyrakshit/monai-integration/runs/2dr2i4y3' target=\"_blank\">https://wandb.ai/geekyrakshit/monai-integration/runs/2dr2i4y3</a><br/>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 3 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230323_140053-2dr2i4y3/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2q6rKXHzkrsP"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}